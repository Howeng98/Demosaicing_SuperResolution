{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UnderGratuated_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMDC_AnP7jeF",
        "outputId": "38411274-f9c3-4ab7-e353-496ec23ea41b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Dec 19 05:21:59 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkC1adys8ZSx",
        "outputId": "5fa20944-0bbb-4840-ef09-86f6c4c820b5"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "from numpy import asarray\n",
        "import math\n",
        "import copy\n",
        "import os\n",
        "from PIL import Image \n",
        "import cv2\n",
        "\n",
        "patch_size = 64 #input = 64x64\n",
        "label_size = 128 #output = 128x128\n",
        "\n",
        "#get RGGB bayer image\n",
        "def bayer_reverse(img):    \n",
        "    height,width,c = img.shape;\n",
        "    tmp = np.zeros([height,width]);\n",
        "    for i in range( height ):\n",
        "        for j in range( width ):\n",
        "            if i % 2 == 0 :\n",
        "                if j % 2 == 0:\n",
        "                    tmp[i][j] = img[i][j][0];#R\n",
        "                else:\n",
        "                    tmp[i][j] = img[i][j][1];#G\n",
        "            else :\n",
        "                if j % 2 == 0:\n",
        "                    tmp[i][j] = img[i][j][1];#G\n",
        "                else:\n",
        "                    tmp[i][j] = img[i][j][2];#B\n",
        "\n",
        "    return tmp;\n",
        "\n",
        "#split image to prepare the train set\n",
        "def split(img,name):\n",
        "    height,width,c = img.shape;\n",
        "    # print(img.shape)\n",
        "    count = 0;\n",
        "    for i in range(0,height,30):\n",
        "        for j in range(0,width,30):\n",
        "            if( i + label_size < height and j + label_size < width ):\n",
        "                tmp = np.zeros([label_size,label_size,3]);\n",
        "                tmp2 = np.zeros([label_size,label_size,3]);\n",
        "                \n",
        "                tmp = img[ i : i + label_size, j : j + label_size,:];\n",
        "                \n",
        "                #save splite label                \n",
        "                path = 'drive/My Drive/Colab Notebooks/undergraduate_project/label/'+name.split('.')[0] +'_'+str(count)+'.png';\n",
        "                #tmp = tmp/255\n",
        "                im = Image.fromarray(tmp)\n",
        "                #tmp2 = tmp\n",
        "                # print(tmp2.shape)\n",
        "                tmp2[:,:,0] = tmp[:,:,2]\n",
        "                tmp2[:,:,1] = tmp[:,:,1]                \n",
        "                tmp2[:,:,2] = tmp[:,:,0]\n",
        "                #im.save(path)\n",
        "                cv2.imwrite(path,tmp2)\n",
        "\n",
        "                zoom = im.resize((patch_size,patch_size)) \n",
        "                zoom2 = np.zeros([patch_size,patch_size,3]);\n",
        "                gray =  np.zeros([patch_size,patch_size]);\n",
        "                \n",
        "                zoom = np.array(zoom)\n",
        "                zoom2[:,:,0] = zoom[:,:,2]\n",
        "                zoom2[:,:,1] = zoom[:,:,1]                \n",
        "                zoom2[:,:,2] = zoom[:,:,0]\n",
        "                \n",
        "                gray = bayer_reverse(zoom2)\n",
        "                #gray = gray/255                \n",
        "                path = 'drive/My Drive/Colab Notebooks/undergraduate_project/patch/'+name.split('.')[0] +'_'+str(count)+'.png';\n",
        "                im = Image.fromarray(gray)\n",
        "                #im = im.convert(\"L\")\n",
        "                #im.save(path)\n",
        "                cv2.imwrite(path,gray)\n",
        "\n",
        "                count = count + 1\n",
        "\n",
        "def main():\n",
        "        \n",
        "    if not os.path.exists('drive/My Drive/Colab Notebooks/undergraduate_project/patch'):\n",
        "        os.makedirs('drive/My Drive/Colab Notebooks/undergraduate_project/patch')\n",
        "    \n",
        "    if not os.path.exists('drive/My Drive/Colab Notebooks/undergraduate_project/label'):\n",
        "        os.makedirs('drive/My Drive/Colab Notebooks/undergraduate_project/label')\n",
        "    \n",
        "    original_path = 'drive/My Drive/Colab Notebooks/undergraduate_project/koda'\n",
        "    entries = os.listdir(original_path)\n",
        "    for entry in entries:\n",
        "        print(entry)\n",
        "        path = original_path + '/' + entry\n",
        "        img = Image.open(path)\n",
        "        img = np.array(img)\n",
        "        split(img,entry)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kodim01.png\n",
            "kodim02.png\n",
            "kodim03.png\n",
            "kodim04.png\n",
            "kodim05.png\n",
            "kodim07.png\n",
            "kodim06.png\n",
            "kodim08.png\n",
            "kodim09.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8eWs0-w8_fR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42cf5dcb-6839-425d-d207-e472083bc6f0"
      },
      "source": [
        "import numpy as np\n",
        "#from tensorflow.keras import layers\n",
        "from keras.preprocessing import image\n",
        "import tensorflow as tf \n",
        "from keras.models import Model,load_model\n",
        "from keras.utils import to_categorical\n",
        "import os\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras.layers import Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "import random\n",
        "from PIL import Image \n",
        "from random import shuffle\n",
        "\n",
        "batch_sz = 16\n",
        "oti = 'adam'\n",
        "lr = 0.0002\n",
        "e_num = 10\n",
        "\n",
        "\n",
        "#http://ethen8181.github.io/machine-learning/keras/resnet_cam/resnet_cam.html\n",
        "#https://ithelp.ithome.com.tw/articles/10223034\n",
        "\n",
        "\n",
        "# def main():\n",
        "  # train_image = np.load('train_image.npy')\n",
        "  # train_label = np.load('train_label.npy')\n",
        "\n",
        "  # test_image = np.load('test_img.npy')\n",
        "  # test_label = np.load('test_lab.npy')\n",
        "\n",
        "\n",
        "train_image = []\n",
        "train_label = []\n",
        "\n",
        "entries = os.listdir('drive/My Drive/Colab Notebooks/undergraduate_project/patch')\n",
        "for entry in entries:\n",
        "  im = image.load_img('drive/My Drive/Colab Notebooks/undergraduate_project/patch/'+entry, target_size = (64, 64))\n",
        "  img = image.img_to_array(im)\n",
        "  img = img[:,:,0]\n",
        "  img = img[:,:,np.newaxis]\n",
        "  train_image.append(img)\n",
        "train_image= np.stack(train_image)\n",
        "\n",
        "print(train_image.shape)# (x,128,128,1)\n",
        "np.save('train_image',train_image)\n",
        "\n",
        "entries = os.listdir('drive/My Drive/Colab Notebooks/undergraduate_project/label')\n",
        "for entry in entries:\n",
        "  im = image.load_img('drive/My Drive/Colab Notebooks/undergraduate_project/label/'+entry, target_size = (128, 128))\n",
        "  img = image.img_to_array(im)\n",
        "  train_label.append(img)\n",
        "train_label = np.stack(train_label)\n",
        "\n",
        "print(train_label.shape)# (x,256,256,3)\n",
        "\n",
        "np.save('train_label',train_label)\n",
        "\n",
        "index = [i for i in range(train_image.shape[0])]\n",
        "shuffle(index)\n",
        "train_image = train_image[index,:,:,:];\n",
        "train_label = train_label[index,:,:,:];\n",
        "\n",
        "\n",
        "inputs = keras.Input(shape=(None,None,1))\n",
        "\n",
        "##Subpixel Construction\n",
        "sub_layer_2 = Lambda(lambda x:tf.nn.space_to_depth(x,2)) \n",
        "init = sub_layer_2(inputs=inputs)\n",
        "\n",
        "\n",
        "\n",
        "##Learning Residual (DCNN)\n",
        "####Conv 3x3x64x64 + PReLu\n",
        "x = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                    kernel_size = 3, \n",
        "                    strides = 1,  # 2\n",
        "                    padding = 'same', \n",
        "                    input_shape = (None,None,1))(init)\n",
        "\n",
        "x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
        "\n",
        "####Residual Block\n",
        "for i in range(6):\n",
        "  Conv1 = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                      kernel_size = 3, \n",
        "                      strides = 1,  # 2\n",
        "                      padding = 'same',\n",
        "                      input_shape = (None,None,64))(x)\n",
        "  \n",
        "  PReLu = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(Conv1)\n",
        "  Conv2 = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                      kernel_size = 3, \n",
        "                      strides = 1,  # 2\n",
        "                      padding = 'same',\n",
        "                      input_shape = (None,None,64))(PReLu)\n",
        "  \n",
        "  \n",
        "  x = keras.layers.Add()([Conv2,x])\n",
        "  x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
        "####Conv 3x3x64x64 + PReLu\n",
        "x = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                    kernel_size = 3, \n",
        "                    strides = 1,  # 2\n",
        "                    padding = 'same', \n",
        "                    input_shape = (None,None,1))(x)\n",
        "\n",
        "x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
        "####Conv 3x3x64x48\n",
        "x = keras.layers.Conv2D(filters = 48, #feature map number\n",
        "                    kernel_size = 3, \n",
        "                    strides = 1,  \n",
        "                    padding = 'same',                      \n",
        "                    input_shape = (None,None,64))(x)\n",
        "\n",
        "###########Learning Residual (DCNN)############\n",
        "\n",
        "\n",
        "##Recovery From Subpixel\n",
        "sub_layer = Lambda(lambda x:tf.nn.depth_to_space(x,4)) \n",
        "Residual_Output = sub_layer(inputs=x)\n",
        "\n",
        "\n",
        "##Initial Prediction\n",
        "R = Lambda(lambda x: x[:,:,:,0])(init)\n",
        "G = Lambda(lambda x: x[:,:,:,1:3])(init)\n",
        "G = Lambda(lambda x: K.mean(x, axis=3))(G)\n",
        "B = Lambda(lambda x: x[:,:,:,3])(init)\n",
        "print(init.shape)\n",
        "print(R.shape)\n",
        "print(G.shape)\n",
        "print(B.shape)\n",
        "R = Lambda(lambda x: tf.expand_dims(x, -1))(R)\n",
        "G = Lambda(lambda x: tf.expand_dims(x, -1))(G)\n",
        "B = Lambda(lambda x: tf.expand_dims(x, -1))(B)\n",
        "\n",
        "#rgb = tf.keras.backend.stack((R, G,B),axis =  3)\n",
        "print(R.shape)\n",
        "rg = keras.layers.Concatenate(axis = 3)([R , G])\n",
        "rgb = keras.layers.Concatenate(axis = 3)([rg,B])\n",
        "print(rgb.shape)\n",
        "Coarse_Output = keras.layers.UpSampling2D(size=(4, 4))(rgb)\n",
        "\n",
        "\n",
        "## + \n",
        "outputs = keras.layers.Add()([Residual_Output,Coarse_Output])\n",
        "#outputs = Residual_Output\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"JDMSR_model\")\n",
        "model.summary()\n",
        "#model.compile(optimizer=keras.optimizers.Nadam(lr), loss = 'mean_squared_error', metrics = ['mse'])\n",
        "model.compile(optimizer=Adam(lr=0.0002, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#histories = Histories()\n",
        "checkpoint = ModelCheckpoint('./model.hdf5',verbose=1, monitor='val_loss', \n",
        "                              save_best_only=True,save_weights_only=True)\n",
        "rrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='min', min_lr=0.0000002)\n",
        "\n",
        "history = model.fit(train_image, train_label, epochs=e_num, batch_size=batch_sz,verbose=1,\n",
        "            validation_split = 0.1,callbacks=[checkpoint,rrp],shuffle = True)\n",
        "\n",
        "# model.save(\"trashn.h5\")\n",
        "# loss, accuracy = model.evaluate(test_image,test_label)\n",
        "# print(loss)\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6864, 64, 64, 1)\n",
            "(6864, 128, 128, 3)\n",
            "(None, None, None, 4)\n",
            "(None, None, None)\n",
            "(None, None, None)\n",
            "(None, None, None)\n",
            "(None, None, None, 1)\n",
            "(None, None, None, 3)\n",
            "(None, None, None, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shUXwDXu-Sgs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "31c04cca-cf1f-43a1-93df-8efd328c4d42"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plotting\n",
        "fig = plt.figure()\n",
        "plt.plot()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.savefig('model_accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.savefig('model_loss.png')\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-12e0f0808a6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}