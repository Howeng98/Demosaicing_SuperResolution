{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "UnderGraduate_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WIhqrzAFMqT",
        "outputId": "0f4f8e8e-ea0f-4bb9-ad15-c3818288492a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Feb 17 04:41:02 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                  N/A |\n",
            "| N/A   39C    P8     6W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-xZKc2dW7kde",
        "outputId": "b3f642e7-f0b4-4fbb-e735-4ab3c2844798"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5PwooDorNkc"
      },
      "source": [
        "**Prepare**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfOiNyPJFcFY",
        "outputId": "17d7928b-bc76-4eed-a5ec-9b1eae4edeaa"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "from numpy import asarray\n",
        "import math\n",
        "import copy\n",
        "import os\n",
        "from PIL import Image \n",
        "import cv2\n",
        "\n",
        "patch_size = 64 #input = 64x64\n",
        "label_size = 128 #output = 128x128\n",
        "\n",
        "#get RGGB bayer image\n",
        "def bayer_reverse(img):\n",
        "    height,width,c = img.shape;\n",
        "    tmp = np.zeros([height,width]);\n",
        "    for i in range( height ):\n",
        "        for j in range( width ):\n",
        "            if i % 2 == 0 :\n",
        "                if j % 2 == 0:\n",
        "                    tmp[i][j] = img[i][j][0];#R\n",
        "                else:\n",
        "                    tmp[i][j] = img[i][j][1];#G\n",
        "            else :\n",
        "                if j % 2 == 0:\n",
        "                    tmp[i][j] = img[i][j][1];#G\n",
        "                else:\n",
        "                    tmp[i][j] = img[i][j][2];#B\n",
        "\n",
        "    return tmp;\n",
        "\n",
        "#split image to prepare the train set\n",
        "def split(img,name,dir_path):\n",
        "    height,width,c = img.shape;\n",
        "    # print(img.shape)\n",
        "    count = 0;\n",
        "    for i in range(0,height,30):\n",
        "        for j in range(0,width,30):\n",
        "            if( i + label_size < height and j + label_size < width ):\n",
        "                tmp = np.zeros([label_size,label_size,3]);\n",
        "                tmp2 = np.zeros([label_size,label_size,3]);\n",
        "                \n",
        "                tmp = img[ i : i + label_size, j : j + label_size,:];\n",
        "                                \n",
        "                path = os.path.join(dir_path,'label/'+name.split('.')[0] +'_'+str(count)+'.png')                \n",
        "                im = Image.fromarray(tmp)               \n",
        "                tmp2[:,:,0] = tmp[:,:,2]\n",
        "                tmp2[:,:,1] = tmp[:,:,1]                \n",
        "                tmp2[:,:,2] = tmp[:,:,0]                \n",
        "                cv2.imwrite(path,tmp2)\n",
        "\n",
        "                zoom = im.resize((patch_size,patch_size)) \n",
        "                zoom2 = np.zeros([patch_size,patch_size,3]);\n",
        "                # gray =  np.zeros([patch_size,patch_size]);\n",
        "                \n",
        "                zoom = np.array(zoom)\n",
        "                zoom2[:,:,0] = zoom[:,:,2]\n",
        "                zoom2[:,:,1] = zoom[:,:,1]                \n",
        "                zoom2[:,:,2] = zoom[:,:,0]\n",
        "                \n",
        "                # zoom2 = bayer_reverse(zoom2)\n",
        "                #gray = gray/255                \n",
        "                path = os.path.join(dir_path,'patch/'+name.split('.')[0] +'_'+str(count)+'.png')\n",
        "                # im = Image.fromarray(zoom2)           \n",
        "                cv2.imwrite(path, zoom2)\n",
        "\n",
        "                count = count + 1\n",
        "\n",
        "def main():\n",
        "    path = 'drive/My Drive/Colab Notebooks/undergraduate_project'\n",
        "    if not os.path.exists(os.path.join(path,'patch')):\n",
        "        os.makedirs(os.path.join(path,'patch'))\n",
        "    \n",
        "    if not os.path.exists(os.path.join(path,'label')):\n",
        "        os.makedirs(os.path.join(path,'label'))\n",
        "    \n",
        "    dataset_path = os.path.join(path,'origin')\n",
        "    entries = os.listdir(dataset_path)\n",
        "    for entry in entries:\n",
        "        print(entry)\n",
        "        img_path = dataset_path + '/' + entry\n",
        "        img = Image.open(img_path)\n",
        "        img = np.array(img)   \n",
        "        split(img,entry,path)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42078.png\n",
            "92059.png\n",
            "97017.png\n",
            "65019.png\n",
            "56028.png\n",
            "67079.png\n",
            "46076.png\n",
            "95006.png\n",
            "55075.png\n",
            "71046.png\n",
            "45077.png\n",
            "42044.png\n",
            "55067.png\n",
            "61086.png\n",
            "66075.png\n",
            "43083.png\n",
            "61060.png\n",
            "59078.png\n",
            "90076.png\n",
            "80099.png\n",
            "78019.png\n",
            "60079.png\n",
            "66039.png\n",
            "94079.png\n",
            "65074.png\n",
            "65132.png\n",
            "43070.png\n",
            "65010.png\n",
            "68077.png\n",
            "87065.png\n",
            "48055.png\n",
            "54005.png\n",
            "76002.png\n",
            "100075.png\n",
            "105019.png\n",
            "104022.png\n",
            "103041.png\n",
            "105053.png\n",
            "100080.png\n",
            "100098.png\n",
            "106025.png\n",
            "106020.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geAXuo4nrFWD"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_SV9g9WWp9d",
        "outputId": "273abac8-13c3-4e77-ea1d-61b7c3ac59ea"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing import image\n",
        "import tensorflow as tf \n",
        "from keras.models import Model,load_model\n",
        "from keras.utils import to_categorical\n",
        "import os\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras.layers import Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "import random\n",
        "from PIL import Image \n",
        "from random import shuffle\n",
        "\n",
        "batch_sz = 16\n",
        "oti = 'adam'\n",
        "lr = 0.0001\n",
        "e_num = 20\n",
        "\n",
        "#http://ethen8181.github.io/machine-learning/keras/resnet_cam/resnet_cam.html\n",
        "#https://ithelp.ithome.com.tw/articles/10223034\n",
        "\n",
        "\n",
        "def main():\n",
        "  # train_image = np.load('train_image.npy')\n",
        "  # train_label = np.load('train_label.npy')\n",
        "\n",
        "  # test_image = np.load('test_img.npy')\n",
        "  # test_label = np.load('test_lab.npy')\n",
        "\n",
        "  train_image = []\n",
        "  train_label = []\n",
        "\n",
        "  dir_path = 'drive/My Drive/Colab Notebooks/undergraduate_project'\n",
        "  patch_path = os.path.join(dir_path,'patch')\n",
        "  entries = os.listdir(patch_path)\n",
        "  for entry in entries:\n",
        "    im = image.load_img(patch_path+'/'+entry, target_size = (64, 64))\n",
        "    img = image.img_to_array(im)    \n",
        "    # img = img[:,:,0]    \n",
        "    # img = img[:,:,np.newaxis]           # Modify here!!!\n",
        "    train_image.append(img)\n",
        "  train_image= np.stack(train_image)\n",
        "\n",
        "  print(train_image.shape)# (x,128,128,1)\n",
        "  # np.save('train_image',train_image)     \n",
        "\n",
        "  label_path = os.path.join(dir_path,'label')\n",
        "  entries = os.listdir(label_path)\n",
        "  for entry in entries:\n",
        "    im = image.load_img(label_path+'/'+entry, target_size = (128, 128))\n",
        "    img = image.img_to_array(im)\n",
        "    train_label.append(img)\n",
        "  train_label = np.stack(train_label)\n",
        "\n",
        "  print(train_label.shape)# (x,256,256,3)\n",
        "  \n",
        "  # np.save('train_label',train_label)\n",
        "\n",
        "  index = [i for i in range(train_image.shape[0])]\n",
        "  shuffle(index)\n",
        "  train_image = train_image[index,:,:,:];\n",
        "  train_label = train_label[index,:,:,:];\n",
        "\n",
        "\n",
        "  inputs = keras.Input(shape=(None,None,3))\n",
        "\n",
        "  ##Subpixel Construction\n",
        "  sub_layer_2 = Lambda(lambda x:tf.nn.space_to_depth(x,2)) \n",
        "  init = sub_layer_2(inputs=inputs)\n",
        "\n",
        "\n",
        "  ##Learning Residual (DCNN)\n",
        "  ####Conv 3x3x64x64 + PReLu\n",
        "  x = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                     kernel_size = 3, \n",
        "                     strides = 1,  # 2\n",
        "                     padding = 'same', \n",
        "                     input_shape = (None,None,3))(init)\n",
        "  \n",
        "  x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
        "\n",
        "  ####Residual Block\n",
        "  for i in range(6):\n",
        "    Conv1 = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                       kernel_size = 3, \n",
        "                       strides = 1,  # 2\n",
        "                       padding = 'same',\n",
        "                       input_shape = (None,None,64))(x)\n",
        "    \n",
        "    PReLu = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(Conv1)\n",
        "    Conv2 = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                       kernel_size = 3, \n",
        "                       strides = 1,  # 2\n",
        "                       padding = 'same',\n",
        "                       input_shape = (None,None,64))(PReLu)\n",
        "   \n",
        "    \n",
        "    x = keras.layers.Add()([Conv2,x])\n",
        "    x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
        "\n",
        "  ####Conv 3x3x64x64 + PReLu\n",
        "  x = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                     kernel_size = 3, \n",
        "                     strides = 1,  # 2\n",
        "                     padding = 'same', \n",
        "                     input_shape = (None,None,1))(x)\n",
        "  \n",
        "  x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
        "  \n",
        "  ####Conv 3x3x64x48\n",
        "  x = keras.layers.Conv2D(filters = 48, #feature map number\n",
        "                     kernel_size = 3, \n",
        "                     strides = 1,  \n",
        "                     padding = 'same',                      \n",
        "                     input_shape = (None,None,64))(x)\n",
        "  \n",
        "  ###########Learning Residual (DCNN)############\n",
        "  \n",
        "  ##Recovery From Subpixel\n",
        "  sub_layer = Lambda(lambda x:tf.nn.depth_to_space(x,4)) \n",
        "  Residual_Output = sub_layer(inputs=x)\n",
        "  \n",
        "\n",
        "  ##Initial Prediction\n",
        "  R = Lambda(lambda x: x[:,:,:,0])(init)\n",
        "  G = Lambda(lambda x: x[:,:,:,1:3])(init)\n",
        "  G = Lambda(lambda x: K.mean(x, axis=3))(G)\n",
        "  B = Lambda(lambda x: x[:,:,:,3])(init)\n",
        "  # print(init.shape)\n",
        "  # print(R.shape)\n",
        "  # print(G.shape)\n",
        "  # print(B.shape)\n",
        "  R = Lambda(lambda x: tf.expand_dims(x, -1))(R)\n",
        "  G = Lambda(lambda x: tf.expand_dims(x, -1))(G)\n",
        "  B = Lambda(lambda x: tf.expand_dims(x, -1))(B)\n",
        "  \n",
        "  #rgb = tf.keras.backend.stack((R, G,B),axis =  3)\n",
        "  # print(R.shape)\n",
        "  rg = keras.layers.Concatenate(axis = 3)([R , G])\n",
        "  rgb = keras.layers.Concatenate(axis = 3)([rg,B])\n",
        "  # print(rgb.shape)\n",
        "  Coarse_Output = keras.layers.UpSampling2D(size=(4, 4))(rgb)\n",
        "\n",
        "\n",
        "\n",
        "  ## + \n",
        "  outputs = keras.layers.Add()([Residual_Output,Coarse_Output])\n",
        " \n",
        "  model = keras.Model(inputs=inputs, outputs=outputs, name=\"JDMSR_model\")\n",
        "  model.summary()\n",
        "  model.compile(optimizer=Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss = 'mean_squared_error', metrics = ['mse'])\n",
        "  \n",
        "  #histories = Histories()\n",
        "  checkpoint = ModelCheckpoint(os.path.join(dir_path,'model.hdf5'),verbose=1, monitor='val_loss', \n",
        "                                save_best_only=True,save_weights_only=True)\n",
        "  rrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='min', min_lr=0.0000002)\n",
        "\n",
        "  history = model.fit(train_image, train_label, epochs=e_num, batch_size=batch_sz,verbose=1,\n",
        "              validation_split = 0.1,callbacks=[checkpoint,rrp],shuffle = True)\n",
        "  model.save(os.path.join(dir_path,'model.h5'))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3528, 64, 64, 3)\n",
            "(3528, 128, 128, 3)\n",
            "Model: \"JDMSR_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, None, None, 1 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, None, None, 6 6976        lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu (PReLU)                 (None, None, None, 6 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 6 36928       p_re_lu[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_1 (PReLU)               (None, None, None, 6 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 6 36928       p_re_lu_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, None, None, 6 0           conv2d_2[0][0]                   \n",
            "                                                                 p_re_lu[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_2 (PReLU)               (None, None, None, 6 64          add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 6 36928       p_re_lu_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_3 (PReLU)               (None, None, None, 6 64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 6 36928       p_re_lu_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 6 0           conv2d_4[0][0]                   \n",
            "                                                                 p_re_lu_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_4 (PReLU)               (None, None, None, 6 64          add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 6 36928       p_re_lu_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_5 (PReLU)               (None, None, None, 6 64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 6 36928       p_re_lu_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 6 0           conv2d_6[0][0]                   \n",
            "                                                                 p_re_lu_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_6 (PReLU)               (None, None, None, 6 64          add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 6 36928       p_re_lu_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_7 (PReLU)               (None, None, None, 6 64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 6 36928       p_re_lu_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 6 0           conv2d_8[0][0]                   \n",
            "                                                                 p_re_lu_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_8 (PReLU)               (None, None, None, 6 64          add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 6 36928       p_re_lu_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_9 (PReLU)               (None, None, None, 6 64          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 6 36928       p_re_lu_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 6 0           conv2d_10[0][0]                  \n",
            "                                                                 p_re_lu_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_10 (PReLU)              (None, None, None, 6 64          add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 6 36928       p_re_lu_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_11 (PReLU)              (None, None, None, 6 64          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 6 36928       p_re_lu_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 6 0           conv2d_12[0][0]                  \n",
            "                                                                 p_re_lu_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, None, None, 2 0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_12 (PReLU)              (None, None, None, 6 64          add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, None, None)   0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, None, None)   0           lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 6 36928       p_re_lu_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, None, None, 1 0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, None, None, 1 0           lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, None, None)   0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_13 (PReLU)              (None, None, None, 6 64          conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, None, None, 2 0           lambda_6[0][0]                   \n",
            "                                                                 lambda_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, None, None, 1 0           lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 4 27696       p_re_lu_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 3 0           concatenate[0][0]                \n",
            "                                                                 lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, None, None, 3 0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, None, None, 3 0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 3 0           lambda_1[0][0]                   \n",
            "                                                                 up_sampling2d[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 515,632\n",
            "Trainable params: 515,632\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "199/199 [==============================] - 16s 41ms/step - loss: 1474.2259 - mse: 1474.2259 - val_loss: 544.4134 - val_mse: 544.4134\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 544.41339, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 2/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 459.0476 - mse: 459.0476 - val_loss: 342.4925 - val_mse: 342.4925\n",
            "\n",
            "Epoch 00002: val_loss improved from 544.41339 to 342.49249, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 3/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 302.7044 - mse: 302.7044 - val_loss: 268.8328 - val_mse: 268.8328\n",
            "\n",
            "Epoch 00003: val_loss improved from 342.49249 to 268.83282, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 4/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 246.6069 - mse: 246.6069 - val_loss: 238.7520 - val_mse: 238.7520\n",
            "\n",
            "Epoch 00004: val_loss improved from 268.83282 to 238.75201, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 5/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 220.4035 - mse: 220.4035 - val_loss: 215.4005 - val_mse: 215.4005\n",
            "\n",
            "Epoch 00005: val_loss improved from 238.75201 to 215.40054, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 6/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 200.3976 - mse: 200.3976 - val_loss: 202.0361 - val_mse: 202.0361\n",
            "\n",
            "Epoch 00006: val_loss improved from 215.40054 to 202.03612, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 7/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 186.3945 - mse: 186.3945 - val_loss: 189.0517 - val_mse: 189.0517\n",
            "\n",
            "Epoch 00007: val_loss improved from 202.03612 to 189.05173, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 8/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 180.2205 - mse: 180.2205 - val_loss: 178.0956 - val_mse: 178.0956\n",
            "\n",
            "Epoch 00008: val_loss improved from 189.05173 to 178.09557, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 9/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 169.8646 - mse: 169.8646 - val_loss: 171.5001 - val_mse: 171.5001\n",
            "\n",
            "Epoch 00009: val_loss improved from 178.09557 to 171.50014, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 10/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 158.4632 - mse: 158.4632 - val_loss: 164.8675 - val_mse: 164.8675\n",
            "\n",
            "Epoch 00010: val_loss improved from 171.50014 to 164.86751, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 11/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 158.9430 - mse: 158.9430 - val_loss: 156.9302 - val_mse: 156.9302\n",
            "\n",
            "Epoch 00011: val_loss improved from 164.86751 to 156.93019, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 12/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 149.9190 - mse: 149.9190 - val_loss: 152.5309 - val_mse: 152.5309\n",
            "\n",
            "Epoch 00012: val_loss improved from 156.93019 to 152.53093, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 13/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 147.4727 - mse: 147.4727 - val_loss: 151.0083 - val_mse: 151.0083\n",
            "\n",
            "Epoch 00013: val_loss improved from 152.53093 to 151.00830, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 14/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 142.7027 - mse: 142.7027 - val_loss: 145.8788 - val_mse: 145.8788\n",
            "\n",
            "Epoch 00014: val_loss improved from 151.00830 to 145.87880, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 15/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 140.3261 - mse: 140.3261 - val_loss: 142.2586 - val_mse: 142.2586\n",
            "\n",
            "Epoch 00015: val_loss improved from 145.87880 to 142.25864, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 16/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 134.7686 - mse: 134.7686 - val_loss: 140.7217 - val_mse: 140.7217\n",
            "\n",
            "Epoch 00016: val_loss improved from 142.25864 to 140.72168, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 17/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 132.7236 - mse: 132.7236 - val_loss: 137.2020 - val_mse: 137.2020\n",
            "\n",
            "Epoch 00017: val_loss improved from 140.72168 to 137.20204, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 18/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 132.2567 - mse: 132.2567 - val_loss: 134.4353 - val_mse: 134.4353\n",
            "\n",
            "Epoch 00018: val_loss improved from 137.20204 to 134.43535, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 19/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 129.4416 - mse: 129.4416 - val_loss: 133.6605 - val_mse: 133.6605\n",
            "\n",
            "Epoch 00019: val_loss improved from 134.43535 to 133.66054, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 20/20\n",
            "199/199 [==============================] - 8s 39ms/step - loss: 127.8248 - mse: 127.8248 - val_loss: 131.7740 - val_mse: 131.7740\n",
            "\n",
            "Epoch 00020: val_loss improved from 133.66054 to 131.77399, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSBqGz65q-7S"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcbfQPmoq2W1",
        "outputId": "5ef92029-ab0e-4a7a-b9d0-eef2610497d0"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.layers import Lambda\n",
        "from keras.preprocessing import image\n",
        "import keras\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image \n",
        "from keras import backend as K\n",
        "import os\n",
        "import math\n",
        "oti = 'adam'\n",
        "\n",
        "def create_model():\n",
        "  inputs = keras.Input(shape=(None,None,3))\n",
        "\n",
        "  ##Subpixel Construction\n",
        "  sub_layer_2 = Lambda(lambda x:tf.nn.space_to_depth(x,2)) \n",
        "  init = sub_layer_2(inputs=inputs)\n",
        "\n",
        "\n",
        "\n",
        "  ##Learning Residual (DCNN)\n",
        "  ####Conv 3x3x64x64 + PReLu\n",
        "  x = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                     kernel_size = 3, \n",
        "                     strides = 1,  # 2\n",
        "                     padding = 'same', \n",
        "                     input_shape = (None,None,3))(init)\n",
        "  \n",
        "  x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
        "\n",
        "  ####Residual Block\n",
        "  for i in range(6):\n",
        "    Conv1 = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                       kernel_size = 3, \n",
        "                       strides = 1,  # 2\n",
        "                       padding = 'same',\n",
        "                       input_shape = (None,None,64))(x)\n",
        "    \n",
        "    PReLu = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(Conv1)\n",
        "    Conv2 = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                       kernel_size = 3, \n",
        "                       strides = 1,  # 2\n",
        "                       padding = 'same',\n",
        "                       input_shape = (None,None,64))(PReLu)\n",
        "   \n",
        "    \n",
        "    x = keras.layers.Add()([Conv2,x])\n",
        "    x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
        "  ####Conv 3x3x64x64 + PReLu\n",
        "  x = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                     kernel_size = 3, \n",
        "                     strides = 1,  # 2\n",
        "                     padding = 'same', \n",
        "                     input_shape = (None,None,1))(x)\n",
        "  \n",
        "  x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
        "  ####Conv 3x3x64x48\n",
        "  x = keras.layers.Conv2D(filters = 48, #feature map number\n",
        "                     kernel_size = 3, \n",
        "                     strides = 1,  \n",
        "                     padding = 'same',                      \n",
        "                     input_shape = (None,None,64))(x)\n",
        "  \n",
        "  ###########Learning Residual (DCNN)############\n",
        "\n",
        "  ##Recovery From Subpixel\n",
        "  sub_layer = Lambda(lambda x:tf.nn.depth_to_space(x,4)) \n",
        "  Residual_Output = sub_layer(inputs=x)\n",
        "  \n",
        "\n",
        "  ##Initial Prediction\n",
        "  R = Lambda(lambda x: x[:,:,:,0])(init)\n",
        "  G = Lambda(lambda x: x[:,:,:,1:3])(init)\n",
        "  G = Lambda(lambda x: K.mean(x, axis=3))(G)\n",
        "  B = Lambda(lambda x: x[:,:,:,3])(init)\n",
        "  # print(init.shape)\n",
        "  # print(R.shape)\n",
        "  # print(G.shape)\n",
        "  # print(B.shape)\n",
        "  R = Lambda(lambda x: tf.expand_dims(x, -1))(R)\n",
        "  G = Lambda(lambda x: tf.expand_dims(x, -1))(G)\n",
        "  B = Lambda(lambda x: tf.expand_dims(x, -1))(B)\n",
        "  \n",
        "  #rgb = tf.keras.backend.stack((R, G,B),axis =  3)\n",
        "  # print(R.shape)\n",
        "  rg = keras.layers.Concatenate(axis = 3)([R , G])\n",
        "  rgb = keras.layers.Concatenate(axis = 3)([rg,B])\n",
        "  # print(rgb.shape)\n",
        "  Coarse_Output = keras.layers.UpSampling2D(size=(4, 4))(rgb)\n",
        "\n",
        "  outputs = keras.layers.Add()([Residual_Output,Coarse_Output])\n",
        " \n",
        "  model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
        "  return model\n",
        "\n",
        "dir_path = 'drive/My Drive/Colab Notebooks/undergraduate_project'\n",
        "model = create_model()\n",
        "model.load_weights(os.path.join(dir_path,'model.hdf5'))\n",
        "\n",
        "\n",
        "kodaout = os.path.join(dir_path, 'kodaout')\n",
        "if not os.path.exists(kodaout):\n",
        "        os.makedirs(kodaout)\n",
        "\n",
        "kodain = os.path.join(dir_path, 'koda')\n",
        "entries = os.listdir(kodain)\n",
        "for entry in entries:\n",
        "    # Test Image\n",
        "    path = kodain+'/'+entry\n",
        "    test_image = Image.open(path)\n",
        "    print(test_image.size)\n",
        "    test_image = test_image.resize((test_image.size[0]//2, test_image.size[1]//2), Image.BILINEAR)\n",
        "    print(test_image.size)\n",
        "    test_image = np.array(test_image)\n",
        "    print(test_image.shape)\n",
        "    test_image = test_image[np.newaxis,:,:]\n",
        "    print(test_image.shape)\n",
        "\n",
        "    out = model.predict(test_image)\n",
        "    out = out[0]   \n",
        "    out = image.array_to_img(out)\n",
        "    path = kodaout+'/'+entry\n",
        "    out.save(path)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(512, 768)\n",
            "(256, 384)\n",
            "(384, 256, 3)\n",
            "(1, 384, 256, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(512, 768)\n",
            "(256, 384)\n",
            "(384, 256, 3)\n",
            "(1, 384, 256, 3)\n",
            "(512, 768)\n",
            "(256, 384)\n",
            "(384, 256, 3)\n",
            "(1, 384, 256, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(512, 768)\n",
            "(256, 384)\n",
            "(384, 256, 3)\n",
            "(1, 384, 256, 3)\n",
            "(512, 768)\n",
            "(256, 384)\n",
            "(384, 256, 3)\n",
            "(1, 384, 256, 3)\n",
            "(512, 768)\n",
            "(256, 384)\n",
            "(384, 256, 3)\n",
            "(1, 384, 256, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n",
            "(768, 512)\n",
            "(384, 256)\n",
            "(256, 384, 3)\n",
            "(1, 256, 384, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzVpCLEFoX8T",
        "outputId": "9eb28501-6851-4906-b56a-14976b74160b"
      },
      "source": [
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import os\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from skimage.measure import compare_ssim\r\n",
        "\r\n",
        "def calculate_psnr(original, contrast):\r\n",
        "    mse = np.mean((original - contrast) ** 2)\r\n",
        "    if mse == 0:\r\n",
        "        return 100\r\n",
        "    max_value = 255.0\r\n",
        "    return 20 * math.log10(max_value / math.sqrt(mse))\r\n",
        "    \r\n",
        "\r\n",
        "path = 'drive/My Drive/Colab Notebooks/undergraduate_project' \r\n",
        "input_path = os.path.join(path,'koda')\r\n",
        "output_path = os.path.join(path,'kodaout')\r\n",
        "entries = os.listdir(input_path)\r\n",
        "count = 0\r\n",
        "total_psnr = 0.\r\n",
        "total_ssim = 0.\r\n",
        "\r\n",
        "for entry in entries:\r\n",
        "  img1 = cv2.imread(os.path.join(input_path,entry))\r\n",
        "  img2 = cv2.imread(os.path.join(output_path,entry))\r\n",
        "  # img1 = cv2.resize(img1, (img2.shape[1], img2.shape[0]), interpolation=cv2.INTER_CUBIC)\r\n",
        "  psnr = calculate_psnr(img1,img2)\r\n",
        "  print(\"PSNR-{0}: {1:.10f}dB\".format(entry,psnr))\r\n",
        "  ssim = compare_ssim(img1, img2, multichannel=True)\r\n",
        "  print(\"SSIM-{0}: {1:.10f}\".format(entry,ssim))\r\n",
        "  total_psnr += psnr\r\n",
        "  total_ssim += ssim\r\n",
        "  count += 1\r\n",
        "print(count)\r\n",
        "# cv2_imshow(img1)\r\n",
        "# cv2_imshow(img2)\r\n",
        "\r\n",
        "total_psnr = total_psnr / count\r\n",
        "total_ssim = total_ssim / count\r\n",
        "print(\"\\n=====================================\")\r\n",
        "print(\"Average PSNR:{:.10f}\".format(total_psnr))\r\n",
        "print(\"Average SSIM:{:.10f}\".format(total_ssim))\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PSNR-kodim01.png: 29.4876033846dB\n",
            "SSIM-kodim01.png: 0.7167695854\n",
            "PSNR-kodim02.png: 28.6417166007dB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SSIM-kodim02.png: 0.7850120941\n",
            "PSNR-kodim03.png: 28.3243515302dB\n",
            "SSIM-kodim03.png: 0.8404275479\n",
            "PSNR-kodim04.png: 31.2251869056dB\n",
            "SSIM-kodim04.png: 0.8464220104\n",
            "PSNR-kodim05.png: 28.9098128818dB\n",
            "SSIM-kodim05.png: 0.7561124723\n",
            "PSNR-kodim07.png: 31.0357224670dB\n",
            "SSIM-kodim07.png: 0.9000563238\n",
            "PSNR-kodim06.png: 29.4091253460dB\n",
            "SSIM-kodim06.png: 0.7729614579\n",
            "PSNR-kodim08.png: 28.7009069817dB\n",
            "SSIM-kodim08.png: 0.7409519906\n",
            "PSNR-kodim09.png: 30.5383448061dB\n",
            "SSIM-kodim09.png: 0.8721981835\n",
            "PSNR-kodim10.png: 28.0667277049dB\n",
            "SSIM-kodim10.png: 0.8625777833\n",
            "PSNR-kodim11.png: 29.6319469953dB\n",
            "SSIM-kodim11.png: 0.7831349345\n",
            "PSNR-kodim12.png: 29.0939296405dB\n",
            "SSIM-kodim12.png: 0.8571261434\n",
            "PSNR-kodim14.png: 28.6482851561dB\n",
            "SSIM-kodim14.png: 0.7464715059\n",
            "PSNR-kodim13.png: 28.8154000003dB\n",
            "SSIM-kodim13.png: 0.6554379741\n",
            "PSNR-kodim15.png: 28.2976967629dB\n",
            "SSIM-kodim15.png: 0.8218277353\n",
            "PSNR-kodim16.png: 32.6335597900dB\n",
            "SSIM-kodim16.png: 0.8330166911\n",
            "PSNR-kodim17.png: 29.8285834212dB\n",
            "SSIM-kodim17.png: 0.8520728534\n",
            "PSNR-kodim19.png: 29.8445377007dB\n",
            "SSIM-kodim19.png: 0.8117604237\n",
            "PSNR-kodim18.png: 30.2841269726dB\n",
            "SSIM-kodim18.png: 0.7717089504\n",
            "PSNR-kodim20.png: 27.8698372226dB\n",
            "SSIM-kodim20.png: 0.8453627907\n",
            "PSNR-kodim21.png: 28.5384982611dB\n",
            "SSIM-kodim21.png: 0.8315620463\n",
            "PSNR-kodim22.png: 28.3962756670dB\n",
            "SSIM-kodim22.png: 0.7814028057\n",
            "PSNR-kodim23.png: 28.7931311756dB\n",
            "SSIM-kodim23.png: 0.8819399776\n",
            "PSNR-kodim24.png: 27.7615893553dB\n",
            "SSIM-kodim24.png: 0.7759733272\n",
            "24\n",
            "\n",
            "=====================================\n",
            "Average PSNR:29.2823706971\n",
            "Average SSIM:0.8059286503\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}