{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "UnderGraduate_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WIhqrzAFMqT"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xZKc2dW7kde"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5PwooDorNkc"
      },
      "source": [
        "**Prepare**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfOiNyPJFcFY"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "from numpy import asarray\n",
        "import math\n",
        "import copy\n",
        "import os\n",
        "from PIL import Image \n",
        "import cv2\n",
        "\n",
        "patch_size = 64 #input = 64x64\n",
        "label_size = 128 #output = 128x128\n",
        "\n",
        "#get RGGB bayer image\n",
        "def bayer_reverse(img):\n",
        "    height,width,c = img.shape;\n",
        "    tmp = np.zeros([height,width]);\n",
        "    for i in range( height ):\n",
        "        for j in range( width ):\n",
        "            if i % 2 == 0 :\n",
        "                if j % 2 == 0:\n",
        "                    tmp[i][j] = img[i][j][0];#R\n",
        "                else:\n",
        "                    tmp[i][j] = img[i][j][1];#G\n",
        "            else :\n",
        "                if j % 2 == 0:\n",
        "                    tmp[i][j] = img[i][j][1];#G\n",
        "                else:\n",
        "                    tmp[i][j] = img[i][j][2];#B\n",
        "\n",
        "    return tmp;\n",
        "\n",
        "#split image to prepare the train set\n",
        "def split(img,name,dir_path):\n",
        "    height,width,c = img.shape;\n",
        "    # print(img.shape)\n",
        "    count = 0;\n",
        "    for i in range(0,height,30):\n",
        "        for j in range(0,width,30):\n",
        "            if( i + label_size < height and j + label_size < width ):\n",
        "                tmp = np.zeros([label_size,label_size,3]);\n",
        "                tmp2 = np.zeros([label_size,label_size,3]);\n",
        "                \n",
        "                tmp = img[ i : i + label_size, j : j + label_size,:];\n",
        "                                \n",
        "                path = os.path.join(dir_path,'label/'+name.split('.')[0] +'_'+str(count)+'.png')                \n",
        "                im = Image.fromarray(tmp)               \n",
        "                tmp2[:,:,0] = tmp[:,:,2]\n",
        "                tmp2[:,:,1] = tmp[:,:,1]                \n",
        "                tmp2[:,:,2] = tmp[:,:,0]                \n",
        "                cv2.imwrite(path,tmp2)\n",
        "\n",
        "                zoom = im.resize((patch_size,patch_size)) \n",
        "                zoom2 = np.zeros([patch_size,patch_size,3]);\n",
        "                # gray =  np.zeros([patch_size,patch_size]);\n",
        "                \n",
        "                zoom = np.array(zoom)\n",
        "                zoom2[:,:,0] = zoom[:,:,2]\n",
        "                zoom2[:,:,1] = zoom[:,:,1]                \n",
        "                zoom2[:,:,2] = zoom[:,:,0]\n",
        "                \n",
        "                # zoom2 = bayer_reverse(zoom2)\n",
        "                #gray = gray/255                \n",
        "                path = os.path.join(dir_path,'patch/'+name.split('.')[0] +'_'+str(count)+'.png')\n",
        "                # im = Image.fromarray(zoom2)           \n",
        "                cv2.imwrite(path, zoom2)\n",
        "\n",
        "                count = count + 1\n",
        "\n",
        "def main():\n",
        "    path = 'drive/My Drive/Colab Notebooks/undergraduate_project'\n",
        "    if not os.path.exists(os.path.join(path,'patch')):\n",
        "        os.makedirs(os.path.join(path,'patch'))\n",
        "    \n",
        "    if not os.path.exists(os.path.join(path,'label')):\n",
        "        os.makedirs(os.path.join(path,'label'))\n",
        "    \n",
        "    dataset_path = os.path.join(path,'origin')\n",
        "    entries = os.listdir(dataset_path)\n",
        "    for entry in entries:\n",
        "        print(entry)\n",
        "        img_path = dataset_path + '/' + entry\n",
        "        img = Image.open(img_path)\n",
        "        img = np.array(img)   \n",
        "        split(img,entry,path)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geAXuo4nrFWD"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_SV9g9WWp9d"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing import image\n",
        "import tensorflow as tf \n",
        "from keras.models import Model,load_model\n",
        "from keras.utils import to_categorical\n",
        "import os\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras.layers import Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "import random\n",
        "from PIL import Image \n",
        "from random import shuffle\n",
        "\n",
        "batch_sz = 16\n",
        "oti = 'adam'\n",
        "lr = 0.001\n",
        "e_num = 20\n",
        "\n",
        "\n",
        "# def main():\n",
        "\n",
        "train_image = []\n",
        "train_label = []\n",
        "\n",
        "dir_path = 'drive/My Drive/Colab Notebooks/undergraduate_project'\n",
        "patch_path = os.path.join(dir_path,'patch')\n",
        "entries = os.listdir(patch_path)\n",
        "for entry in entries:\n",
        "  im = image.load_img(patch_path+'/'+entry, target_size = (64, 64))\n",
        "  img = image.img_to_array(im)    \n",
        "  # img = img[:,:,0]    \n",
        "  # img = img[:,:,np.newaxis]           # Modify here!!!\n",
        "  train_image.append(img)\n",
        "train_image= np.stack(train_image)\n",
        "\n",
        "print(train_image.shape)# (x,128,128,1)\n",
        "  \n",
        "\n",
        "label_path = os.path.join(dir_path,'label')\n",
        "entries = os.listdir(label_path)\n",
        "for entry in entries:\n",
        "  im = image.load_img(label_path+'/'+entry, target_size = (128, 128))\n",
        "  img = image.img_to_array(im)\n",
        "  train_label.append(img)\n",
        "train_label = np.stack(train_label)\n",
        "\n",
        "print(train_label.shape)# (x,256,256,3)\n",
        "\n",
        "\n",
        "\n",
        "index = [i for i in range(train_image.shape[0])]\n",
        "shuffle(index)\n",
        "train_image = train_image[index,:,:,:];\n",
        "train_label = train_label[index,:,:,:];\n",
        "\n",
        "# model.save(os.path.join(dir_path,'model.h5'))\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#   main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqW1Fluq1Ou7"
      },
      "source": [
        "############################# Model Structure ################################################\r\n",
        "def create_model():\r\n",
        "  inputs = keras.Input(shape=(None,None,3))\r\n",
        "\r\n",
        "  ##Subpixel Construction\r\n",
        "  sub_layer_2 = Lambda(lambda x:tf.nn.space_to_depth(x,2)) \r\n",
        "  init = sub_layer_2(inputs=inputs)\r\n",
        "\r\n",
        "\r\n",
        "  ##Learning Residual (DCNN)\r\n",
        "  ####Conv 3x3x64x64 + PReLu\r\n",
        "  x = keras.layers.Conv2D(filters=64,\r\n",
        "                      kernel_size = 3, \r\n",
        "                      strides = 1,  # 2\r\n",
        "                      padding = 'same', \r\n",
        "                      input_shape = (None,None,3))(init)\r\n",
        "\r\n",
        "  x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\r\n",
        "\r\n",
        "  ####Residual Block\r\n",
        "  for i in range(6):\r\n",
        "    Conv1 = keras.layers.SeparableConv2D(filters=64,\r\n",
        "                        kernel_size = 3, \r\n",
        "                        strides = 1,  # 2\r\n",
        "                        padding = 'same',\r\n",
        "                        input_shape = (None,None,64))(x)\r\n",
        "    \r\n",
        "    PReLu = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(Conv1)\r\n",
        "    Conv2 = keras.layers.SeparableConv2D(filters=64,\r\n",
        "                        kernel_size = 3, \r\n",
        "                        strides = 1,  # 2\r\n",
        "                        padding = 'same',\r\n",
        "                        input_shape = (None,None,64))(PReLu)\r\n",
        "    \r\n",
        "    \r\n",
        "    x = keras.layers.Add()([Conv2,x])\r\n",
        "    x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\r\n",
        "\r\n",
        "  ####Conv 3x3x64x64 + PReLu\r\n",
        "  x = keras.layers.Conv2D(filters=64,\r\n",
        "                      kernel_size = 3, \r\n",
        "                      strides = 1,  # 2\r\n",
        "                      padding = 'same', \r\n",
        "                      input_shape = (None,None,1))(x)\r\n",
        "\r\n",
        "  x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\r\n",
        "\r\n",
        "  ####Conv 3x3x64x48\r\n",
        "  x = keras.layers.SeparableConv2D(filters=48,\r\n",
        "                      kernel_size = 3, \r\n",
        "                      strides = 1,  \r\n",
        "                      padding = 'same',                      \r\n",
        "                      input_shape = (None,None,64))(x)\r\n",
        "\r\n",
        "  ###########Learning Residual (DCNN)############\r\n",
        "\r\n",
        "  ##Recovery From Subpixel\r\n",
        "  sub_layer = Lambda(lambda x:tf.nn.depth_to_space(x,4)) \r\n",
        "  Residual_Output = sub_layer(inputs=x)\r\n",
        "\r\n",
        "\r\n",
        "  ##Initial Prediction\r\n",
        "  R = Lambda(lambda x: x[:,:,:,0])(init)\r\n",
        "  G = Lambda(lambda x: x[:,:,:,1:3])(init)\r\n",
        "  G = Lambda(lambda x: K.mean(x, axis=3))(G)\r\n",
        "  B = Lambda(lambda x: x[:,:,:,3])(init)\r\n",
        "  # print(init.shape)\r\n",
        "  # print(R.shape)\r\n",
        "  # print(G.shape)\r\n",
        "  # print(B.shape)\r\n",
        "  R = Lambda(lambda x: tf.expand_dims(x, -1))(R)\r\n",
        "  G = Lambda(lambda x: tf.expand_dims(x, -1))(G)\r\n",
        "  B = Lambda(lambda x: tf.expand_dims(x, -1))(B)\r\n",
        "\r\n",
        "  #rgb = tf.keras.backend.stack((R, G,B),axis =  3)\r\n",
        "  # print(R.shape)\r\n",
        "  rg = keras.layers.Concatenate(axis = 3)([R , G])\r\n",
        "  rgb = keras.layers.Concatenate(axis = 3)([rg,B])\r\n",
        "  # print(rgb.shape)\r\n",
        "  Coarse_Output = keras.layers.UpSampling2D(size=(4, 4))(rgb)\r\n",
        "\r\n",
        "  ## + \r\n",
        "  outputs = keras.layers.Add()([Residual_Output,Coarse_Output])\r\n",
        "\r\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs, name=\"JDMSR_model\")  \r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsNBcy5C1Sgy"
      },
      "source": [
        "model = create_model()\r\n",
        "model.compile(optimizer=Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss = 'mean_squared_error', metrics = ['accuracy'])\r\n",
        "\r\n",
        "#histories = Histories()\r\n",
        "checkpoint = ModelCheckpoint(os.path.join(dir_path,'model.hdf5'),verbose=1, monitor='val_loss', \r\n",
        "                              save_best_only=True,save_weights_only=True)\r\n",
        "rrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='min', min_lr=0.0000002)\r\n",
        "\r\n",
        "history = model.fit(train_image, train_label, epochs=e_num, batch_size=batch_sz,verbose=1,\r\n",
        "            validation_split = 0.1,callbacks=[checkpoint,rrp],shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TVUNhlptZdZ"
      },
      "source": [
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "plt.plot()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy - 2')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.savefig('model_accuracy2.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss - 2')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.savefig('model_loss2.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSBqGz65q-7S"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcbfQPmoq2W1",
        "outputId": "ebcdedf6-fbb2-4ac1-922e-aa9d497a7370"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.layers import Lambda\n",
        "from keras.preprocessing import image\n",
        "import keras\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image \n",
        "from keras import backend as K\n",
        "import os\n",
        "import math\n",
        "import shutil\n",
        "oti = 'adam'\n",
        "\n",
        "\n",
        "dir_path = 'drive/My Drive/Colab Notebooks/undergraduate_project'\n",
        "model = create_model()\n",
        "model.load_weights(os.path.join(dir_path,'model.hdf5'))\n",
        "\n",
        "\n",
        "output_path = os.path.join(dir_path, 'output')\n",
        "output_path2 = os.path.join(dir_path, 'output2')\n",
        "\n",
        "if os.path.exists(output_path):\n",
        "    shutil.rmtree(output_path)\n",
        "os.makedirs(output_path)\n",
        "\n",
        "if os.path.exists(output_path2):\n",
        "    shutil.rmtree(output_path2)\n",
        "os.makedirs(output_path2)\n",
        "\n",
        "input_path = os.path.join(dir_path, 'Set14')\n",
        "entries = os.listdir(input_path)\n",
        "\n",
        "print(\"--------  Start Validation --------\")\n",
        "for entry in entries:\n",
        "    # Test Image\n",
        "    path = input_path+'/'+entry\n",
        "    test_image = Image.open(path)\n",
        "    \n",
        "    if not test_image.size[0]%2 == 0:\n",
        "      test_image = test_image.resize((test_image.size[0]-1, test_image.size[1]), Image.BILINEAR)\n",
        "    if not test_image.size[1]%2 == 0:\n",
        "      test_image = test_image.resize((test_image.size[0], test_image.size[1]-1), Image.BILINEAR)\n",
        "\n",
        "    print(test_image.size)\n",
        "    original_image = test_image.resize((test_image.size[0]*2, test_image.size[1]*2), Image.BILINEAR)\n",
        "    path = output_path2+'/'+entry\n",
        "    original_image.save(path)\n",
        "\n",
        "    print(test_image.size)\n",
        "    test_image = np.array(test_image)\n",
        "    print(test_image.shape)\n",
        "    test_image = test_image[np.newaxis,:,:]\n",
        "    print(test_image.shape)\n",
        "\n",
        "    out = model.predict(test_image)\n",
        "    out = out[0]   \n",
        "    out = image.array_to_img(out)\n",
        "    path = output_path+'/'+entry\n",
        "    out.save(path)\n",
        "print(\"-------- Finish Validation  --------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------  Start Validation --------\n",
            "(276, 276)\n",
            "(276, 276)\n",
            "(276, 276, 3)\n",
            "(1, 276, 276, 3)\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1ca21b5050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "(500, 362)\n",
            "(500, 362)\n",
            "(362, 500, 3)\n",
            "(1, 362, 500, 3)\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1ca21b5050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "(250, 360)\n",
            "(250, 360)\n",
            "(360, 250, 3)\n",
            "(1, 360, 250, 3)\n",
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1ca21b5050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "(512, 512)\n",
            "(512, 512)\n",
            "(512, 512, 3)\n",
            "(1, 512, 512, 3)\n",
            "(528, 656)\n",
            "(528, 656)\n",
            "(656, 528, 3)\n",
            "(1, 656, 528, 3)\n",
            "(500, 480)\n",
            "(500, 480)\n",
            "(480, 500, 3)\n",
            "(1, 480, 500, 3)\n",
            "(512, 512)\n",
            "(512, 512)\n",
            "(512, 512, 3)\n",
            "(1, 512, 512, 3)\n",
            "(720, 576)\n",
            "(720, 576)\n",
            "(576, 720, 3)\n",
            "(1, 576, 720, 3)\n",
            "(352, 288)\n",
            "(352, 288)\n",
            "(288, 352, 3)\n",
            "(1, 288, 352, 3)\n",
            "(512, 512)\n",
            "(512, 512)\n",
            "(512, 512, 3)\n",
            "(1, 512, 512, 3)\n",
            "(352, 288)\n",
            "(352, 288)\n",
            "(288, 352, 3)\n",
            "(1, 288, 352, 3)\n",
            "(768, 512)\n",
            "(768, 512)\n",
            "(512, 768, 3)\n",
            "(1, 512, 768, 3)\n",
            "(512, 512)\n",
            "(512, 512)\n",
            "(512, 512, 3)\n",
            "(1, 512, 512, 3)\n",
            "(586, 390)\n",
            "(586, 390)\n",
            "(390, 586, 3)\n",
            "(1, 390, 586, 3)\n",
            "-------- Finish Validation  --------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY5gyote19PB"
      },
      "source": [
        "**Performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzVpCLEFoX8T",
        "outputId": "7b6cd377-a5c8-4f75-f851-df9a78677dce"
      },
      "source": [
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import os\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from skimage.measure import compare_ssim\r\n",
        "\r\n",
        "def calculate_psnr(original, contrast):\r\n",
        "    mse = np.mean((original - contrast) ** 2)\r\n",
        "    if mse == 0:\r\n",
        "        return 100\r\n",
        "    max_value = 255.0\r\n",
        "    return 20 * math.log10(max_value / math.sqrt(mse))\r\n",
        "    \r\n",
        "\r\n",
        "path = 'drive/My Drive/Colab Notebooks/undergraduate_project' \r\n",
        "input_path = os.path.join(path,'output')\r\n",
        "output_path = os.path.join(path,'output2')\r\n",
        "entries = os.listdir(input_path)\r\n",
        "count = 0\r\n",
        "total_psnr = 0.\r\n",
        "total_ssim = 0.\r\n",
        "\r\n",
        "for entry in entries:\r\n",
        "  img1 = cv2.imread(os.path.join(input_path,entry))\r\n",
        "  img2 = cv2.imread(os.path.join(output_path,entry))\r\n",
        "  # img1 = cv2.resize(img1, (img2.shape[1], img2.shape[0]), interpolation=cv2.INTER_CUBIC)\r\n",
        "  psnr = calculate_psnr(img1,img2)\r\n",
        "  print(\"PSNR-{0}: {1:.10f}dB\".format(entry,psnr))\r\n",
        "  ssim = compare_ssim(img1, img2, multichannel=True)\r\n",
        "  print(\"SSIM-{0}: {1:.10f}\".format(entry,ssim))\r\n",
        "  total_psnr += psnr\r\n",
        "  total_ssim += ssim\r\n",
        "  count += 1\r\n",
        "print(count)\r\n",
        "# cv2_imshow(img1)\r\n",
        "# cv2_imshow(img2)\r\n",
        "\r\n",
        "total_psnr = total_psnr / count\r\n",
        "total_ssim = total_ssim / count\r\n",
        "print(\"\\n=====================================\")\r\n",
        "print(\"Average PSNR:{:.10f}\".format(total_psnr))\r\n",
        "print(\"Average SSIM:{:.10f}\".format(total_ssim))\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PSNR-face.png: 28.3243303750dB\n",
            "SSIM-face.png: 0.7639348999\n",
            "PSNR-flowers.png: 28.0414611060dB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SSIM-flowers.png: 0.8585437544\n",
            "PSNR-comic.png: 28.8671512143dB\n",
            "SSIM-comic.png: 0.9386269585\n",
            "PSNR-bridge.png: 28.8560914818dB\n",
            "SSIM-bridge.png: 0.9170089340\n",
            "PSNR-ppt3.png: 27.4606706123dB\n",
            "SSIM-ppt3.png: 0.8509819235\n",
            "PSNR-baboon.png: 27.9018888841dB\n",
            "SSIM-baboon.png: 0.7656595234\n",
            "PSNR-lenna.png: 30.0393172850dB\n",
            "SSIM-lenna.png: 0.8992952384\n",
            "PSNR-barbara.png: 28.3207661045dB\n",
            "SSIM-barbara.png: 0.8946657592\n",
            "PSNR-coastguard.png: 28.1006749768dB\n",
            "SSIM-coastguard.png: 0.9458464889\n",
            "PSNR-man.png: 28.4855418540dB\n",
            "SSIM-man.png: 0.7856137805\n",
            "PSNR-foreman.png: 27.9806757549dB\n",
            "SSIM-foreman.png: 0.9367705249\n",
            "PSNR-monarch.png: 29.9128844973dB\n",
            "SSIM-monarch.png: 0.9629333332\n",
            "PSNR-pepper.png: 28.0542032723dB\n",
            "SSIM-pepper.png: 0.8059124542\n",
            "PSNR-zebra.png: 29.2695414434dB\n",
            "SSIM-zebra.png: 0.9286183603\n",
            "14\n",
            "\n",
            "=====================================\n",
            "Average PSNR:28.5439427758\n",
            "Average SSIM:0.8753151381\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}