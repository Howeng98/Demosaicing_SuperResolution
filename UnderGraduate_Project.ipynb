{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UnderGraduate_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WIhqrzAFMqT"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xZKc2dW7kde"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5PMYUZu3NP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea4bb32-e7c2-4d87-aaff-8517557b8bf5"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing import image\n",
        "import tensorflow as tf \n",
        "from keras.models import Model,load_model\n",
        "from keras.utils import to_categorical\n",
        "import os\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
        "from keras.layers import Lambda\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import random\n",
        "from PIL import Image \n",
        "from random import shuffle\n",
        "%load_ext tensorboard\n",
        "import datetime\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5PwooDorNkc"
      },
      "source": [
        "**Prepare**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfOiNyPJFcFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efdc9d41-6902-4202-d542-2ed6f251fcea"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "from numpy import asarray\n",
        "import math\n",
        "import copy\n",
        "import os\n",
        "from PIL import Image \n",
        "import cv2\n",
        "import shutil\n",
        "\n",
        "patch_size = 64 #input = 64x64\n",
        "label_size = 128 #output = 128x128\n",
        "\n",
        "#get RGGB bayer image\n",
        "def bayer_reverse(img):\n",
        "    height,width,c = img.shape;\n",
        "    tmp = np.zeros([height,width]);\n",
        "    for i in range( height ):\n",
        "        for j in range( width ):\n",
        "            if i % 2 == 0 :\n",
        "                if j % 2 == 0:\n",
        "                    tmp[i][j] = img[i][j][0];#R\n",
        "                else:\n",
        "                    tmp[i][j] = img[i][j][1];#G\n",
        "            else :\n",
        "                if j % 2 == 0:\n",
        "                    tmp[i][j] = img[i][j][1];#G\n",
        "                else:\n",
        "                    tmp[i][j] = img[i][j][2];#B\n",
        "\n",
        "    return tmp;\n",
        "\n",
        "#split image to prepare the train set\n",
        "def split(img,name,dir_path):\n",
        "    height,width,c = img.shape;    \n",
        "    count = 0;\n",
        "\n",
        "    for i in range(0, height, 30):\n",
        "        for j in range(0, width, 30):\n",
        "            if( i + label_size < height and j + label_size < width ):                \n",
        "                label = np.zeros([label_size,label_size,3])                \n",
        "                tmp2  = np.zeros([label_size,label_size,3])                \n",
        "                tmp2 = img[ i : i + label_size, j : j + label_size,:]\n",
        "                label_img = Image.fromarray(tmp2)\n",
        "\n",
        "                label[:,:,0] = tmp2[:,:,2]\n",
        "                label[:,:,1] = tmp2[:,:,1]\n",
        "                label[:,:,2] = tmp2[:,:,0]\n",
        "                label_path = os.path.join(dir_path,'label/'+name.split('.')[0] +'_'+str(count)+'.png')                                                \n",
        "                cv2.imwrite(label_path,label)\n",
        "\n",
        "                \n",
        "                zoom = label_img.resize((patch_size,patch_size), Image.BICUBIC)                 \n",
        "                tmp3 = np.zeros([patch_size,patch_size])\n",
        "                patch = np.zeros([patch_size,patch_size])\n",
        "\n",
        "                \n",
        "                zoom2 = np.array(zoom)                \n",
        "                patch = bayer_reverse(zoom2)                \n",
        "                                           \n",
        "                patch_path = os.path.join(dir_path,'patch/'+name.split('.')[0] +'_'+str(count)+'.png')                          \n",
        "                cv2.imwrite(patch_path, patch)\n",
        "\n",
        "                count = count + 1    \n",
        "\n",
        "def main():\n",
        "    path = 'drive/My Drive/Colab Notebooks/undergraduate_project'\n",
        "\n",
        "    if os.path.exists(os.path.join(path,'patch')):\n",
        "      shutil.rmtree(os.path.join(path,'patch'))\n",
        "    os.makedirs(os.path.join(path,'patch'))\n",
        "\n",
        "    if os.path.exists(os.path.join(path,'label')):\n",
        "      shutil.rmtree(os.path.join(path,'label'))\n",
        "    os.makedirs(os.path.join(path,'label'))\n",
        "\n",
        "\n",
        "    dataset_path = os.path.join(path,'BSD')\n",
        "    entries = os.listdir(dataset_path)\n",
        "    for entry in entries:\n",
        "        print(entry)\n",
        "        img_path = dataset_path + '/' + entry\n",
        "        img = Image.open(img_path)\n",
        "        img = np.array(img)   \n",
        "        split(img,entry,path)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "249087.png\n",
            "227040.png\n",
            "246053.png\n",
            "225017.png\n",
            "232038.png\n",
            "216066.png\n",
            "249061.png\n",
            "247085.png\n",
            "245051.png\n",
            "254033.png\n",
            "239007.png\n",
            "253036.png\n",
            "246016.png\n",
            "236017.png\n",
            "238011.png\n",
            "231015.png\n",
            "239096.png\n",
            "227046.png\n",
            "242078.png\n",
            "100098.png\n",
            "104022.png\n",
            "100075.png\n",
            "103041.png\n",
            "106020.png\n",
            "108073.png\n",
            "100080.png\n",
            "108041.png\n",
            "105019.png\n",
            "105053.png\n",
            "106025.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geAXuo4nrFWD"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_SV9g9WWp9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7369adc-e2a8-4369-80d5-526a0de99598"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing import image\n",
        "import tensorflow as tf \n",
        "from keras.models import Model,load_model\n",
        "from keras.utils import to_categorical\n",
        "import os\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau, EarlyStopping\n",
        "from keras.layers import Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "import random\n",
        "from PIL import Image \n",
        "from random import shuffle\n",
        "\n",
        "train_image = []\n",
        "train_label = []\n",
        "patch_size = 64 #input = 64x64\n",
        "label_size = 128 #output = 128x128\n",
        "\n",
        "dir_path = 'drive/My Drive/Colab Notebooks/undergraduate_project'\n",
        "patch_path = os.path.join(dir_path,'patch')\n",
        "entries = os.listdir(patch_path)\n",
        "for entry in entries:\n",
        "  # im = image.load_img(patch_path+'/'+entry, target_size = (patch_size, patch_size))\n",
        "  im = Image.open(patch_path+'/'+entry)\n",
        "  img = image.img_to_array(im)\n",
        "  # print(img.shape)\n",
        "  # img = img/255.\n",
        "  train_image.append(img)\n",
        "train_image= np.stack(train_image)\n",
        "\n",
        "print(train_image.shape)\n",
        "  \n",
        "\n",
        "label_path = os.path.join(dir_path,'label')\n",
        "entries = os.listdir(label_path)\n",
        "for entry in entries:\n",
        "  # im = image.load_img(label_path+'/'+entry, target_size = (label_size, label_size))\n",
        "  im = Image.open(label_path+'/'+entry)\n",
        "  img = image.img_to_array(im)\n",
        "  # img = img/255.\n",
        "  train_label.append(img)\n",
        "train_label = np.stack(train_label)\n",
        "\n",
        "print(train_label.shape)\n",
        "\n",
        "\n",
        "\n",
        "# index = [i for i in range(train_image.shape[0])]\n",
        "# shuffle(index)\n",
        "# train_image = train_image[index,:,:,:];\n",
        "# train_label = train_label[index,:,:,:];\n",
        "\n",
        "# np.save('drive/My Drive/Colab Notebooks/undergraduate_project/train_image.npy', train_image)\n",
        "# np.save('drive/My Drive/Colab Notebooks/undergraduate_project/train_label.npy', train_label)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2520, 64, 64, 1)\n",
            "(2520, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ClU51qwkcz3"
      },
      "source": [
        "############################# Model Structure ################################################\n",
        "def create_model():\n",
        "  inputs = keras.Input(shape=(None,None,1))\n",
        "\n",
        "  ##Subpixel Construction\n",
        "  sub_layer_2 = Lambda(lambda x:tf.nn.space_to_depth(x,2)) \n",
        "  init = sub_layer_2(inputs=inputs)\n",
        "\n",
        "\n",
        "\n",
        "  ##Learning Residual (DCNN)\n",
        "  ####Conv 3x3x64x64 + PReLu\n",
        "  x = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                     kernel_size = 3, \n",
        "                     strides = 1,  # 2\n",
        "                     padding = 'same', \n",
        "                     activation = 'relu',\n",
        "                     input_shape = (None,None,1))(init)\n",
        "  x = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                     kernel_size = 3, \n",
        "                     strides = 1,  # 2\n",
        "                     padding = 'same', \n",
        "                     activation = 'relu',\n",
        "                     input_shape = (None,None,64))(x)\n",
        "  x = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                     kernel_size = 3, \n",
        "                     strides = 1,  # 2\n",
        "                     padding = 'same', \n",
        "                     activation = 'relu',\n",
        "                     input_shape = (None,None,64))(x)\n",
        "  \n",
        "  # x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
        "\n",
        "  ####Residual Block\n",
        "  for i in range(6):\n",
        "    Conv1 = keras.layers.Conv2D(filters=64,\n",
        "                        kernel_size = 1, \n",
        "                        strides = 1,  # 2\n",
        "                        padding = 'same',\n",
        "                        activation = 'relu',\n",
        "                        input_shape = (None,None,64))(x)    \n",
        "    # Conv1_BN = keras.layers.BatchNormalization()(Conv1)\n",
        "    # Conv1_BN = Dropout(0.5)(Conv1_BN)\n",
        "    \n",
        "    # PReLu = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(Conv1)\n",
        "    Conv2 = keras.layers.Conv2D(filters=64,\n",
        "                        kernel_size = 3, \n",
        "                        strides = 1,  # 2\n",
        "                        padding = 'same',\n",
        "                        activation = 'relu',\n",
        "                        input_shape = (None,None,64))(Conv1)\n",
        "    # Conv2_BN = keras.layers.BatchNormalization()(Conv2)\n",
        "    # Conv2_BN = Dropout(0.5)(Conv2_BN)                        \n",
        "    # PReLu = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(Conv2)\n",
        "    Conv3 = keras.layers.Conv2D(filters=64,\n",
        "                        kernel_size = 1, \n",
        "                        strides = 1,  # 2\n",
        "                        padding = 'same',\n",
        "                        activation = 'relu',\n",
        "                        input_shape = (None,None,64))(Conv2)\n",
        "\n",
        "\n",
        "  ####Conv 3x3x64x64 + PReLu\n",
        "  x = keras.layers.Conv2D(filters = 64, #feature map number\n",
        "                     kernel_size = 3, \n",
        "                     strides = 1,  # 2\n",
        "                     padding = 'same',\n",
        "                     activation = 'relu',\n",
        "                     input_shape = (None,None,1))(Conv3)\n",
        "  \n",
        "  # x = keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
        "  ####Conv 3x3x64x48\n",
        "  x = keras.layers.Conv2D(filters = 48, #feature map number\n",
        "                     kernel_size = 3, \n",
        "                     strides = 1,  \n",
        "                     padding = 'same',\n",
        "                     activation = 'relu',                   \n",
        "                     input_shape = (None,None,64))(x)\n",
        "  \n",
        "  ###########Learning Residual (DCNN)############\n",
        "  \n",
        "\n",
        "  ##Recovery From Subpixel\n",
        "  sub_layer = Lambda(lambda x:tf.nn.depth_to_space(x,4)) \n",
        "  Residual_Output = sub_layer(inputs=x)\n",
        "  \n",
        "\n",
        "  ##Initial Prediction\n",
        "  R = Lambda(lambda x: x[:,:,:,0])(init)\n",
        "  G = Lambda(lambda x: x[:,:,:,1:3])(init)\n",
        "  G = Lambda(lambda x: K.mean(x, axis=3))(G)\n",
        "  B = Lambda(lambda x: x[:,:,:,3])(init)\n",
        "  print(init.shape)\n",
        "  print(R.shape)\n",
        "  print(G.shape)\n",
        "  print(B.shape)\n",
        "  R = Lambda(lambda x: tf.expand_dims(x, -1))(R)\n",
        "  G = Lambda(lambda x: tf.expand_dims(x, -1))(G)\n",
        "  B = Lambda(lambda x: tf.expand_dims(x, -1))(B)\n",
        "  \n",
        "  #rgb = tf.keras.backend.stack((R, G,B),axis =  3)\n",
        "  print(R.shape)\n",
        "  rg = keras.layers.Concatenate(axis = 3)([R , G])\n",
        "  rgb = keras.layers.Concatenate(axis = 3)([rg,B])\n",
        "  print(rgb.shape)\n",
        "  Coarse_Output = keras.layers.UpSampling2D(size=(4, 4), interpolation=\"bilinear\")(rgb)\n",
        "\n",
        "\n",
        "  ## + \n",
        "  outputs = keras.layers.Add()([Residual_Output,Coarse_Output])\n",
        "  #outputs = Residual_Output\n",
        " \n",
        "  model = keras.Model(inputs=inputs, outputs=outputs, name=\"JDMSR_model\")\n",
        "  return model"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V3myfmR3UaX"
      },
      "source": [
        "batch_size = 32\n",
        "lr = 0.001\n",
        "e_num = 50\n",
        "dir_path = 'drive/My Drive/Colab Notebooks/undergraduate_project'"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsNBcy5C1Sgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d6a3c7-344b-48ad-debb-cad6e9102641"
      },
      "source": [
        "model = create_model()\n",
        "model.summary()\n",
        "\n",
        "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=1.0)\n",
        "model.compile(optimizer=Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "\n",
        "checkpoint = ModelCheckpoint(os.path.join(dir_path,'model.hdf5'),verbose=1, monitor='val_loss', save_best_only=True,save_weights_only=True)\n",
        "# rrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='min', min_lr=0.0000002)\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=1, mode='auto')\n",
        "\n",
        "# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "history = model.fit(train_image, train_label, epochs=e_num, batch_size=batch_size,verbose=1,validation_split = 0.1,callbacks=[checkpoint, early_stopping],shuffle = False)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, None, 4)\n",
            "(None, None, None)\n",
            "(None, None, None)\n",
            "(None, None, None)\n",
            "(None, None, None, 1)\n",
            "(None, None, None, 3)\n",
            "Model: \"JDMSR_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_108 (Lambda)             (None, None, None, 4 0           input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, None, None, 6 2368        lambda_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, None, None, 6 36928       conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, None, None, 6 36928       conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, None, None, 6 4160        conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_111 (Lambda)             (None, None, None, 2 0           lambda_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, None, None, 6 36928       conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_110 (Lambda)             (None, None, None)   0           lambda_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_112 (Lambda)             (None, None, None)   0           lambda_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, None, None, 6 4160        conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_114 (Lambda)             (None, None, None, 1 0           lambda_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_115 (Lambda)             (None, None, None, 1 0           lambda_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_113 (Lambda)             (None, None, None)   0           lambda_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, None, None, 6 36928       conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, None, None, 2 0           lambda_114[0][0]                 \n",
            "                                                                 lambda_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_116 (Lambda)             (None, None, None, 1 0           lambda_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, None, None, 4 27696       conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, None, None, 3 0           concatenate_24[0][0]             \n",
            "                                                                 lambda_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_109 (Lambda)             (None, None, None, 3 0           conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_12 (UpSampling2D) (None, None, None, 3 0           concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_70 (Add)                    (None, None, None, 3 0           lambda_109[0][0]                 \n",
            "                                                                 up_sampling2d_12[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 186,096\n",
            "Trainable params: 186,096\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "71/71 [==============================] - 2s 22ms/step - loss: 315.8785 - accuracy: 0.8685 - val_loss: 100.8286 - val_accuracy: 0.8757\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 100.82861, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 2/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 278.4106 - accuracy: 0.8739 - val_loss: 93.7161 - val_accuracy: 0.8830\n",
            "\n",
            "Epoch 00002: val_loss improved from 100.82861 to 93.71612, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 3/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 260.6657 - accuracy: 0.8776 - val_loss: 90.5916 - val_accuracy: 0.8738\n",
            "\n",
            "Epoch 00003: val_loss improved from 93.71612 to 90.59164, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 4/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 250.6329 - accuracy: 0.8783 - val_loss: 85.4947 - val_accuracy: 0.8928\n",
            "\n",
            "Epoch 00004: val_loss improved from 90.59164 to 85.49471, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 5/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 243.6736 - accuracy: 0.8805 - val_loss: 86.1987 - val_accuracy: 0.8930\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 85.49471\n",
            "Epoch 6/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 238.9146 - accuracy: 0.8816 - val_loss: 82.1773 - val_accuracy: 0.8964\n",
            "\n",
            "Epoch 00006: val_loss improved from 85.49471 to 82.17725, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 7/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 235.0445 - accuracy: 0.8832 - val_loss: 81.8768 - val_accuracy: 0.8913\n",
            "\n",
            "Epoch 00007: val_loss improved from 82.17725 to 81.87675, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 8/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 231.6215 - accuracy: 0.8841 - val_loss: 80.5755 - val_accuracy: 0.8937\n",
            "\n",
            "Epoch 00008: val_loss improved from 81.87675 to 80.57553, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 9/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 229.5300 - accuracy: 0.8848 - val_loss: 80.8528 - val_accuracy: 0.8876\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 80.57553\n",
            "Epoch 10/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 228.5204 - accuracy: 0.8841 - val_loss: 79.4725 - val_accuracy: 0.8906\n",
            "\n",
            "Epoch 00010: val_loss improved from 80.57553 to 79.47254, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 11/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 227.2194 - accuracy: 0.8848 - val_loss: 78.8822 - val_accuracy: 0.8932\n",
            "\n",
            "Epoch 00011: val_loss improved from 79.47254 to 78.88216, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 12/50\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 224.3019 - accuracy: 0.8851 - val_loss: 78.9265 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 78.88216\n",
            "Epoch 13/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 223.7305 - accuracy: 0.8867 - val_loss: 78.1630 - val_accuracy: 0.8913\n",
            "\n",
            "Epoch 00013: val_loss improved from 78.88216 to 78.16302, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 14/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 222.5232 - accuracy: 0.8869 - val_loss: 77.9045 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00014: val_loss improved from 78.16302 to 77.90453, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 15/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 222.9486 - accuracy: 0.8868 - val_loss: 78.1861 - val_accuracy: 0.8933\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 77.90453\n",
            "Epoch 16/50\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 222.1931 - accuracy: 0.8863 - val_loss: 77.0006 - val_accuracy: 0.9014\n",
            "\n",
            "Epoch 00016: val_loss improved from 77.90453 to 77.00056, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 17/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 220.2810 - accuracy: 0.8883 - val_loss: 77.5423 - val_accuracy: 0.9012\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 77.00056\n",
            "Epoch 18/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 220.2569 - accuracy: 0.8888 - val_loss: 77.3198 - val_accuracy: 0.8959\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 77.00056\n",
            "Epoch 19/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 219.3924 - accuracy: 0.8887 - val_loss: 78.1360 - val_accuracy: 0.8936\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 77.00056\n",
            "Epoch 20/50\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 220.1429 - accuracy: 0.8892 - val_loss: 76.8447 - val_accuracy: 0.8969\n",
            "\n",
            "Epoch 00020: val_loss improved from 77.00056 to 76.84468, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 21/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 219.0231 - accuracy: 0.8897 - val_loss: 76.8256 - val_accuracy: 0.8963\n",
            "\n",
            "Epoch 00021: val_loss improved from 76.84468 to 76.82559, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 22/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 218.1723 - accuracy: 0.8899 - val_loss: 76.9668 - val_accuracy: 0.8949\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 76.82559\n",
            "Epoch 23/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 218.1879 - accuracy: 0.8902 - val_loss: 77.2327 - val_accuracy: 0.8871\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 76.82559\n",
            "Epoch 24/50\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 217.9705 - accuracy: 0.8901 - val_loss: 76.6614 - val_accuracy: 0.8922\n",
            "\n",
            "Epoch 00024: val_loss improved from 76.82559 to 76.66145, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 25/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 217.4050 - accuracy: 0.8903 - val_loss: 76.6570 - val_accuracy: 0.8956\n",
            "\n",
            "Epoch 00025: val_loss improved from 76.66145 to 76.65702, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 26/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 217.1959 - accuracy: 0.8906 - val_loss: 77.2398 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 76.65702\n",
            "Epoch 27/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 217.5769 - accuracy: 0.8905 - val_loss: 76.5145 - val_accuracy: 0.9020\n",
            "\n",
            "Epoch 00027: val_loss improved from 76.65702 to 76.51448, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 28/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 216.9115 - accuracy: 0.8907 - val_loss: 76.0605 - val_accuracy: 0.9013\n",
            "\n",
            "Epoch 00028: val_loss improved from 76.51448 to 76.06049, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 29/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 216.5439 - accuracy: 0.8909 - val_loss: 76.3872 - val_accuracy: 0.9016\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 76.06049\n",
            "Epoch 30/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 216.5068 - accuracy: 0.8908 - val_loss: 77.1476 - val_accuracy: 0.8887\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 76.06049\n",
            "Epoch 31/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 216.5845 - accuracy: 0.8907 - val_loss: 76.5585 - val_accuracy: 0.8961\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 76.06049\n",
            "Epoch 32/50\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 216.4146 - accuracy: 0.8909 - val_loss: 76.4005 - val_accuracy: 0.8930\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 76.06049\n",
            "Epoch 33/50\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 215.5357 - accuracy: 0.8917 - val_loss: 76.2614 - val_accuracy: 0.8930\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 76.06049\n",
            "Epoch 34/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 216.9554 - accuracy: 0.8913 - val_loss: 76.2548 - val_accuracy: 0.8977\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 76.06049\n",
            "Epoch 35/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 216.2970 - accuracy: 0.8917 - val_loss: 75.8733 - val_accuracy: 0.8998\n",
            "\n",
            "Epoch 00035: val_loss improved from 76.06049 to 75.87334, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 36/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 215.6776 - accuracy: 0.8918 - val_loss: 75.5764 - val_accuracy: 0.8996\n",
            "\n",
            "Epoch 00036: val_loss improved from 75.87334 to 75.57639, saving model to drive/My Drive/Colab Notebooks/undergraduate_project/model.hdf5\n",
            "Epoch 37/50\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 215.2931 - accuracy: 0.8921 - val_loss: 75.8028 - val_accuracy: 0.8951\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 75.57639\n",
            "Epoch 38/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 214.8516 - accuracy: 0.8921 - val_loss: 75.8937 - val_accuracy: 0.8988\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 75.57639\n",
            "Epoch 39/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 215.3894 - accuracy: 0.8921 - val_loss: 76.3962 - val_accuracy: 0.8952\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 75.57639\n",
            "Epoch 40/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 216.1708 - accuracy: 0.8906 - val_loss: 75.8284 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 75.57639\n",
            "Epoch 41/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 215.0784 - accuracy: 0.8916 - val_loss: 75.7334 - val_accuracy: 0.8992\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 75.57639\n",
            "Epoch 42/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 215.0729 - accuracy: 0.8917 - val_loss: 76.5488 - val_accuracy: 0.8927\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 75.57639\n",
            "Epoch 43/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 215.8484 - accuracy: 0.8906 - val_loss: 76.9601 - val_accuracy: 0.8922\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 75.57639\n",
            "Epoch 44/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 216.0173 - accuracy: 0.8905 - val_loss: 75.6792 - val_accuracy: 0.9013\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 75.57639\n",
            "Epoch 45/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 214.8597 - accuracy: 0.8925 - val_loss: 75.9196 - val_accuracy: 0.8983\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 75.57639\n",
            "Epoch 46/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 215.3041 - accuracy: 0.8916 - val_loss: 75.9530 - val_accuracy: 0.8932\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 75.57639\n",
            "Epoch 47/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 214.4329 - accuracy: 0.8917 - val_loss: 75.9635 - val_accuracy: 0.8977\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 75.57639\n",
            "Epoch 48/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 213.8468 - accuracy: 0.8923 - val_loss: 76.4495 - val_accuracy: 0.8971\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 75.57639\n",
            "Epoch 49/50\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 213.8211 - accuracy: 0.8923 - val_loss: 75.6553 - val_accuracy: 0.8988\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 75.57639\n",
            "Epoch 50/50\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 213.4328 - accuracy: 0.8927 - val_loss: 75.6506 - val_accuracy: 0.8979\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 75.57639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP1RUVGg_Dng"
      },
      "source": [
        "# %tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TVUNhlptZdZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "1b02f0fb-6225-4dfa-e1bf-89736177e8e9"
      },
      "source": [
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "plt.plot()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy - 2')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.savefig('model_accuracy2.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss - 2')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.savefig('model_loss2.png')\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSBqGz65q-7S"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcbfQPmoq2W1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b652e1-a7c9-4680-de51-15ce1039ade1"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.layers import Lambda\n",
        "from keras.preprocessing import image\n",
        "import keras\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image \n",
        "from keras import backend as K\n",
        "import os\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "width_change = 0\n",
        "height_change = 0\n",
        "\n",
        "dir_path = 'drive/My Drive/Colab Notebooks/undergraduate_project'\n",
        "model = create_model()\n",
        "model.load_weights(os.path.join(dir_path,'model.hdf5'))\n",
        "\n",
        "input_path = os.path.join(dir_path, 'Set5')\n",
        "output_path = os.path.join(dir_path, 'output')\n",
        "output_path2 = os.path.join(dir_path, 'output2')\n",
        "output_path3 = os.path.join(dir_path, 'output3')\n",
        "\n",
        "if os.path.exists(output_path):\n",
        "    shutil.rmtree(output_path)\n",
        "os.makedirs(output_path)\n",
        "\n",
        "if os.path.exists(output_path2):\n",
        "    shutil.rmtree(output_path2)\n",
        "os.makedirs(output_path2)\n",
        "\n",
        "entries = os.listdir(input_path)\n",
        "\n",
        "for entry in entries:\n",
        "    # Test Image\n",
        "    path = input_path+'/'+entry\n",
        "    test_image = Image.open(path)\n",
        "    path = output_path+'/'+entry\n",
        "    test_image.save(path)\n",
        "    \n",
        "    test_image = test_image.resize((test_image.size[0]//2, test_image.size[1]//2), Image.BICUBIC)\n",
        "    # print(test_image.size)\n",
        "    test_image = np.array(test_image)\n",
        "    test_image = bayer_reverse(test_image)\n",
        "    test_image = test_image[:,:,np.newaxis]\n",
        "    test_image = image.array_to_img(test_image)\n",
        "    test_image.save(output_path3+'/'+entry)\n",
        "    # print(test_image.shape)\n",
        "    \n",
        "    \n",
        "    # print(test_image.shape)\n",
        "    test_image = np.array(test_image)\n",
        "    test_image = test_image[np.newaxis,:,:]\n",
        "    out = model.predict(test_image)\n",
        "    # print(out.shape)\n",
        "    out = out[0]\n",
        "    out = image.array_to_img(out)\n",
        "    path = output_path2+'/'+entry\n",
        "    out.save(path)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, None, 4)\n",
            "(None, None, None)\n",
            "(None, None, None)\n",
            "(None, None, None)\n",
            "(None, None, None, 1)\n",
            "(None, None, None, 3)\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f216c6e2e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f216c6e2e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f216c6e2e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f216c6e2e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f216c6e2e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f216c6e2e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY5gyote19PB"
      },
      "source": [
        "**Performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzVpCLEFoX8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af614393-4cfd-45a9-8d18-be54e8dff7a3"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage.measure import compare_ssim\n",
        "\n",
        "def calculate_psnr(original, contrast):\n",
        "    mse = np.mean((original - contrast) ** 2)\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    max_value = 255.0\n",
        "    return 20 * math.log10(max_value / math.sqrt(mse))\n",
        "    \n",
        "\n",
        "path = 'drive/My Drive/Colab Notebooks/undergraduate_project' \n",
        "input_path = os.path.join(path,'output')\n",
        "output_path = os.path.join(path,'output2')\n",
        "entries = os.listdir(input_path)\n",
        "count = 0\n",
        "total_psnr = 0.\n",
        "total_ssim = 0.\n",
        "\n",
        "for entry in entries:\n",
        "  img1 = cv2.imread(os.path.join(input_path,entry))\n",
        "  img2 = cv2.imread(os.path.join(output_path,entry))\n",
        "  # print(img1.shape)\n",
        "  # print(img2.shape)\n",
        "  # img1 = cv2.resize(img1, (img2.shape[1], img2.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
        "  psnr = calculate_psnr(img1,img2)\n",
        "  print(\"PSNR-{0}: {1:.10f}dB\".format(entry,psnr))\n",
        "  ssim = compare_ssim(img1, img2, multichannel=True)\n",
        "  print(\"SSIM-{0}: {1:.10f}\".format(entry,ssim))\n",
        "  total_psnr += psnr\n",
        "  total_ssim += ssim\n",
        "  count += 1\n",
        "print(count)\n",
        "# cv2_imshow(img1)\n",
        "# cv2_imshow(img2)\n",
        "\n",
        "total_psnr = total_psnr / count\n",
        "total_ssim = total_ssim / count\n",
        "print(\"\\n=====================================\")\n",
        "print(\"Average PSNR:{:.10f}\".format(total_psnr))\n",
        "print(\"Average SSIM:{:.10f}\".format(total_ssim))\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PSNR-head.png: 30.9736214497dB\n",
            "SSIM-head.png: 0.7137864352\n",
            "PSNR-bird.png: 29.5853382276dB\n",
            "SSIM-bird.png: 0.8254720072\n",
            "PSNR-baby.png: 31.2790118344dB\n",
            "SSIM-baby.png: 0.8790065600\n",
            "PSNR-butterfly.png: 27.8037086280dB\n",
            "SSIM-butterfly.png: 0.7843813671\n",
            "PSNR-woman.png: 31.6384883432dB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SSIM-woman.png: 0.8634439430\n",
            "5\n",
            "\n",
            "=====================================\n",
            "Average PSNR:30.2560336966\n",
            "Average SSIM:0.8132180625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}